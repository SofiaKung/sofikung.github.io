[["Map",1,2,9,10,500,501],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.17.1","content-config-digest","322ff9e12e7dc060","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://sofikung.com\",\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true,\"allowedDomains\":[]},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"staticImportMetaEnv\":false,\"chromeDevtoolsWorkspace\":false,\"failOnPrerenderConflict\":false,\"svgo\":false},\"legacy\":{\"collections\":false}}","projects",["Map",11,12,50,51,85,86,117,118,154,155,206,207,249,250,295,296,329,330,384,385,422,423],"ai-book-summaries",{"id":11,"data":13,"filePath":35,"digest":36,"rendered":37,"legacyId":49},{"title":14,"date":15,"date_pretty":16,"description":17,"external_link":18,"hero":19,"seo":22,"importance":28,"type":29,"project":30},"BonsaiMind","2025-10-08","Oct 8, 2025","A web app to track books you've read, store highlights, and generate AI-powered book summaries.","https://www.bonsai-mind.com",{"image":20,"alt":21},"assets/bonsaimind.png","A minimalist web app for collecting books, storing highlights, and generating AI summaries.",{"keywords":23,"og_image":20},[24,25,26,27],"AI Summaries","Book Tracker","Web App","Reading Highlights",2,"project",{"tags":31},[32,33,34],"app","supabase","nextjs","src/content/projects/bonsaimind.md","a520da2a69c60484",{"html":38,"metadata":39},"",{"headings":40,"localImagePaths":41,"remoteImagePaths":42,"frontmatter":43,"imagePaths":48},[],[],[],{"title":14,"slug":11,"date":15,"date_pretty":16,"description":17,"importance":28,"type":29,"external_link":18,"hero":44,"project":45,"seo":47},{"image":20,"alt":21},{"tags":46},[32,33,34],{"keywords":23,"og_image":20},[],"bonsaimind.md","visualise-air-quality",{"id":50,"data":52,"body":70,"filePath":71,"digest":72,"rendered":73,"legacyId":84},{"title":53,"date":54,"date_pretty":55,"description":56,"external_link":57,"hero":58,"seo":60,"importance":65,"type":29,"project":66},"Air Quality in Sofia City","2018-11-01","Nov 1, 2018","Analyzing official and citizen-measured air quality in Sofia to uncover patterns, anomalies, and weather links","https://public.tableau.com/app/profile/sofiakung/viz/SofiaAirQuality/AirQualityinSofia",{"image":59,"alt":56},"assets/airquality.png",{"keywords":61,"og_image":64},[62,63],"Visualization","Tableau","assets/fs-ml.jpg",3,{"tags":67},[68,69],"data","tableau","\u003C!-- Optional markdown content can go here. -->","src/content/projects/air-quality.md","8fc0fa27225b74f0",{"html":70,"metadata":74},{"headings":75,"localImagePaths":76,"remoteImagePaths":77,"frontmatter":78,"imagePaths":83},[],[],[],{"title":53,"slug":50,"date":54,"date_pretty":55,"description":56,"importance":65,"type":29,"external_link":57,"hero":79,"project":80,"seo":82},{"image":59,"alt":56},{"tags":81},[68,69],{"keywords":61,"og_image":64},[],"air-quality.md","detect-fs-fraud",{"id":85,"data":87,"body":70,"filePath":103,"digest":104,"rendered":105,"legacyId":116},{"title":88,"date":89,"date_pretty":90,"description":91,"external_link":92,"hero":93,"seo":95,"importance":65,"type":29,"project":99},"Detecting Financial Statement Fraud with ML","2020-05-01","May 1, 2020","How machine learning can detect accounting fraud","https://medium.com/data-science/detecting-firms-with-intentional-misstatements-using-machine-learning-a943191f88cf",{"image":64,"alt":94},"An article on detecting financial statrment fraud with machine learning ",{"keywords":96,"og_image":64},[97,98],"Fraud detection","Machine learning",{"tags":100},[68,101,102],"ai","machine learning","src/content/projects/detect-fs-fraud.md","fea2ab829519d7bd",{"html":70,"metadata":106},{"headings":107,"localImagePaths":108,"remoteImagePaths":109,"frontmatter":110,"imagePaths":115},[],[],[],{"title":88,"slug":85,"date":89,"date_pretty":90,"description":91,"importance":65,"type":29,"external_link":92,"hero":111,"project":112,"seo":114},{"image":64,"alt":94},{"tags":113},[68,101,102],{"keywords":96,"og_image":64},[],"detect-fs-fraud.md","ai-christmas-cards",{"id":117,"data":119,"filePath":140,"digest":141,"rendered":142,"legacyId":153},{"title":120,"date":121,"date_pretty":122,"description":123,"external_link":124,"hero":125,"seo":128,"importance":135,"type":29,"project":136},"JollyCards","2025-11-01","Nov 01, 2025","An AI-powered Christmas card generator that creates personalized festive cards with custom messages and AI-generated imagery.","https://www.jollycards.site",{"image":126,"alt":127},"assets/jollycards.png","AI-generated Christmas cards with personalized messages and festive imagery.",{"keywords":129,"og_image":126},[130,131,132,133,134],"AI Christmas Cards","Personalized Greetings","AI Image Generation","Holiday Cards","Creative AI App",4,{"tags":137},[32,101,138,139],"hackathon","generative ai","src/content/projects/jollycards.md","883730e4c5a0440d",{"html":38,"metadata":143},{"headings":144,"localImagePaths":145,"remoteImagePaths":146,"frontmatter":147,"imagePaths":152},[],[],[],{"title":120,"slug":117,"date":121,"date_pretty":122,"description":123,"importance":135,"type":29,"external_link":124,"hero":148,"project":149,"seo":151},{"image":126,"alt":127},{"tags":150},[32,101,138,139],{"keywords":129,"og_image":126},[],"jollycards.md","content-agent",{"id":154,"data":156,"body":175,"filePath":176,"digest":177,"rendered":178,"legacyId":205},{"title":157,"date":158,"date_pretty":159,"description":160,"hero":161,"seo":164,"importance":170,"type":29,"project":171},"Content Agent","2025-12-01","Dec 01, 2025","I built a content agent that writes for me—here's the 4-step system that actually worked.",{"image":162,"alt":163},"assets/content-agent.png","Content Agent - An AI-powered content writing system with evaluation loops.",{"keywords":165,"og_image":162},[157,166,167,168,169],"AI Writing","Content Strategy","LinkedIn Content","LLM",1,{"tags":172},[101,173,174],"n8n","notion","I built a content agent that writes for me. The first few posts? Generic LinkedIn posts that sound fake.\n\nThe problem was we are not giving enough details for LLM to write specifically to your context, audience and your actual experience.\n\nHere's the 4-step system that actually worked:\n\n## Step 1: Define your content strategy\n\n- Figure out for your profile what kind of content (topic, angle, pain point) your audience is interested in.\n- The content pillar types - Storytelling posts, product updates, educational threads, project showcases.\n- Pick a voice to write in.\n- Generic writing instructions = generic output.\n\n## Step 2: Topic generation with evaluation loops\n\n- Then I feed my content strategy + web search context into the LLM for topic ideas depending what I want to write about.\n- But here's the key: I manually review and record selected topics in a structured format. This is going to be used to improve my prompt strategy over time.\n\n## Step 3: Write with post-type-specific instructions\n\n- For each selected topic, the agent writes using the exact template for that content pillar type.\n- Push the drafts to my Notion for my review.\n\n## Step 4: Feed in your content vault\n\n- Then I feed these drafts with my own content from my content vault.\n- Rewrite the content with a click of a button from my Notion page and then evaluates its own output and reflects on style accuracy before updating the rewritten content in same page.\n\n## Step 5: Competitive analysis on autopilot (Working on it)\n\n- To scrape my own LinkedIn for performance data, then scrape top voices in my space. The agent analyzes their content strategy and suggests style elements worth adopting.\n\n---\n\nThe game-changer? **Treating content agents as your co-author as you open your content vault for it to write on and treating evals as a core feature, not an afterthought.**","src/content/projects/content-agent.md","0eab9feb0d88f8e0",{"html":179,"metadata":180},"\u003Cp>I built a content agent that writes for me. The first few posts? Generic LinkedIn posts that sound fake.\u003C/p>\n\u003Cp>The problem was we are not giving enough details for LLM to write specifically to your context, audience and your actual experience.\u003C/p>\n\u003Cp>Here’s the 4-step system that actually worked:\u003C/p>\n\u003Ch2 id=\"step-1-define-your-content-strategy\">Step 1: Define your content strategy\u003C/h2>\n\u003Cul>\n\u003Cli>Figure out for your profile what kind of content (topic, angle, pain point) your audience is interested in.\u003C/li>\n\u003Cli>The content pillar types - Storytelling posts, product updates, educational threads, project showcases.\u003C/li>\n\u003Cli>Pick a voice to write in.\u003C/li>\n\u003Cli>Generic writing instructions = generic output.\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"step-2-topic-generation-with-evaluation-loops\">Step 2: Topic generation with evaluation loops\u003C/h2>\n\u003Cul>\n\u003Cli>Then I feed my content strategy + web search context into the LLM for topic ideas depending what I want to write about.\u003C/li>\n\u003Cli>But here’s the key: I manually review and record selected topics in a structured format. This is going to be used to improve my prompt strategy over time.\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"step-3-write-with-post-type-specific-instructions\">Step 3: Write with post-type-specific instructions\u003C/h2>\n\u003Cul>\n\u003Cli>For each selected topic, the agent writes using the exact template for that content pillar type.\u003C/li>\n\u003Cli>Push the drafts to my Notion for my review.\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"step-4-feed-in-your-content-vault\">Step 4: Feed in your content vault\u003C/h2>\n\u003Cul>\n\u003Cli>Then I feed these drafts with my own content from my content vault.\u003C/li>\n\u003Cli>Rewrite the content with a click of a button from my Notion page and then evaluates its own output and reflects on style accuracy before updating the rewritten content in same page.\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"step-5-competitive-analysis-on-autopilot-working-on-it\">Step 5: Competitive analysis on autopilot (Working on it)\u003C/h2>\n\u003Cul>\n\u003Cli>To scrape my own LinkedIn for performance data, then scrape top voices in my space. The agent analyzes their content strategy and suggests style elements worth adopting.\u003C/li>\n\u003C/ul>\n\u003Chr>\n\u003Cp>The game-changer? \u003Cstrong>Treating content agents as your co-author as you open your content vault for it to write on and treating evals as a core feature, not an afterthought.\u003C/strong>\u003C/p>",{"headings":181,"localImagePaths":197,"remoteImagePaths":198,"frontmatter":199,"imagePaths":204},[182,185,188,191,194],{"depth":28,"slug":183,"text":184},"step-1-define-your-content-strategy","Step 1: Define your content strategy",{"depth":28,"slug":186,"text":187},"step-2-topic-generation-with-evaluation-loops","Step 2: Topic generation with evaluation loops",{"depth":28,"slug":189,"text":190},"step-3-write-with-post-type-specific-instructions","Step 3: Write with post-type-specific instructions",{"depth":28,"slug":192,"text":193},"step-4-feed-in-your-content-vault","Step 4: Feed in your content vault",{"depth":28,"slug":195,"text":196},"step-5-competitive-analysis-on-autopilot-working-on-it","Step 5: Competitive analysis on autopilot (Working on it)",[],[],{"title":157,"slug":154,"date":158,"date_pretty":159,"description":160,"importance":170,"type":29,"hero":200,"project":201,"seo":203},{"image":162,"alt":163},{"tags":202},[101,173,174],{"keywords":165,"og_image":162},[],"content-agent.md","launchkey",{"id":206,"data":208,"body":227,"filePath":228,"digest":229,"rendered":230,"legacyId":248},{"title":209,"date":210,"date_pretty":211,"description":212,"hero":213,"seo":216,"importance":170,"type":29,"project":223},"LaunchKey","2026-01-11","Jan 11, 2026","We built LaunchKey in 7 hours at Google—here's how I designed the UI fast.",{"image":214,"alt":215},"assets/launchkey.png","LaunchKey - A GTM partner discovery platform built with Firebase, Gemini, Gmail and Maps.",{"keywords":217,"og_image":214},[209,218,219,220,221,222],"GTM Platform","Partner Discovery","UI Design","Google Hackathon","Firebase",{"tags":224},[32,225,138,226],"ui/ux","firebase","LaunchKey helps companies find, vet, and engage partners in overseas markets with Firebase, Gemini, Gmail and Maps.\n\n**My role:** turning GTM workflow logic into a seamless product experience.\n\nThe part I love? The puzzle of process-to-product design:\n\n- How should users move through this workflow?\n- What layouts display options and information in a clean, intuitive way?\n- How do I keep everything in one place—no extra pages, no unnecessary clicks?\n\n## My Toolkit for Speed\n\n**Mobbin** — browsed real B2B patterns for inspiration.\n\n**Stitch** — stitched reference designs together to build wireframes fast.\n\n**Google AI Studio** — turned wireframes into working UI code, ready for integration.\n\n## My Design Workflow\n\nbusiness process → inspiration → wireframes → code\n\n---\n\n- [Demo](https://launchkey.web.app)\n- [Repo (MIT)](https://lnkd.in/g8h--eGN)","src/content/projects/launchkey.md","a15eeb39c2c68597",{"html":231,"metadata":232},"\u003Cp>LaunchKey helps companies find, vet, and engage partners in overseas markets with Firebase, Gemini, Gmail and Maps.\u003C/p>\n\u003Cp>\u003Cstrong>My role:\u003C/strong> turning GTM workflow logic into a seamless product experience.\u003C/p>\n\u003Cp>The part I love? The puzzle of process-to-product design:\u003C/p>\n\u003Cul>\n\u003Cli>How should users move through this workflow?\u003C/li>\n\u003Cli>What layouts display options and information in a clean, intuitive way?\u003C/li>\n\u003Cli>How do I keep everything in one place—no extra pages, no unnecessary clicks?\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"my-toolkit-for-speed\">My Toolkit for Speed\u003C/h2>\n\u003Cp>\u003Cstrong>Mobbin\u003C/strong> — browsed real B2B patterns for inspiration.\u003C/p>\n\u003Cp>\u003Cstrong>Stitch\u003C/strong> — stitched reference designs together to build wireframes fast.\u003C/p>\n\u003Cp>\u003Cstrong>Google AI Studio\u003C/strong> — turned wireframes into working UI code, ready for integration.\u003C/p>\n\u003Ch2 id=\"my-design-workflow\">My Design Workflow\u003C/h2>\n\u003Cp>business process → inspiration → wireframes → code\u003C/p>\n\u003Chr>\n\u003Cul>\n\u003Cli>\u003Ca href=\"https://launchkey.web.app\">Demo\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"https://lnkd.in/g8h--eGN\">Repo (MIT)\u003C/a>\u003C/li>\n\u003C/ul>",{"headings":233,"localImagePaths":240,"remoteImagePaths":241,"frontmatter":242,"imagePaths":247},[234,237],{"depth":28,"slug":235,"text":236},"my-toolkit-for-speed","My Toolkit for Speed",{"depth":28,"slug":238,"text":239},"my-design-workflow","My Design Workflow",[],[],{"title":209,"slug":206,"date":210,"date_pretty":211,"description":212,"importance":170,"type":29,"hero":243,"project":244,"seo":246},{"image":214,"alt":215},{"tags":245},[32,225,138,226],{"keywords":217,"og_image":214},[],"launchkey.md","shiro",{"id":249,"data":251,"body":270,"filePath":271,"digest":272,"rendered":273,"legacyId":294},{"title":252,"date":253,"date_pretty":254,"description":255,"hero":256,"seo":259,"importance":170,"type":29,"project":266},"Shiro","2026-01-16","Jan 16, 2025","My personal AI assistant powered by the Claude Agent SDK—built to prioritize, unblock, and keep me accountable.",{"image":257,"alt":258},"assets/shiro.png","Shiro - A personal AI assistant built with Claude Agent SDK and Notion integration.",{"keywords":260,"og_image":257},[252,261,262,263,264,265],"AI Assistant","Claude Agent SDK","Notion Integration","Personal AI","MCP",{"tags":267},[101,268,269],"claude sdk","python","As someone constantly juggling new ideas, I suffer from \"context overflow.\" Just like an AI agent. I'm often managing multiple projects, scattered research, and half-finished thoughts—the constant context switching was killing my productivity.\n\nTo solve this, I first built Mind Lake—a centralized knowledge system in Notion. It's my single source of truth for every idea, project, and learning. It helped, but it wasn't enough. I realized I didn't just need a place to store info; I needed a system that understood my 2026 goals well enough to prioritize and unblock work for me.\n\nSo, I spent the last 5 days building Shiro: my personal AI assistant powered by the Claude Agent SDK.\n\n## What Shiro Can Do\n\n- **Telegram Interface:** I interact with Shiro via text, treating him like a high-level employee.\n- **Notion Integration:** He searches my Notion workspace to prioritize tasks based on my specific goals and deadlines.\n- **Content Creation:** Draft content for me based on my latest learning in my project.\n- **Active Unblocking:** Shiro asks why tasks are stalling and takes initiative—doing the research or suggesting ways to unblock it.\n- **Daily Accountability:** He sends a priority reminder every morning and a \"check-in\" every night to keep me on track.\n- **Self-Evolving Memory:** He learns from my patterns and develops new Claude Skills (modular prompts) to grow his own capabilities.\n\n**Tech Stack:** Python, Claude Agent SDK, Model Context Protocol (MCP), Docker, Fly.io\n\n## Why Build This?\n\nYou would say why build an AI agent when some of the above can be achieved by Claude chat and Notion MCP? I have learnt so much in the past 5 days building this AI agent and it amazed me.\n\n## What I Learned Shipping It\n\n**Agentic Minimalism:** Don't give your AI agents all the tools and let them pick from it. Define the tools well and when to use them. For example, when it comes to getting data from Notion, MCP is not the best way to get all my active tasks, it was way slower than direct Notion API, in the end I used a hybrid approach.\n\n**The Permission Guardrail:** Early on, I gave Shiro full file write permissions. I was baffled to find new Python files appearing in my local project—turns out Shiro was building his own toolkit to do a better job! I had to implement strict guards. Now, he can only edit his memory and skills, but he cannot touch his core functions (Python files).\n\n**Dynamic nature of AI Agents:** AI agent develops and grows, it would update its learnings and skills on the VM- syncing the ai agent would be key.\n\n---\n\nBuilding Shiro has completely evolved my understanding of AI development.\n\nI had so much fun building this, can't wait to share more! Next would be to use a vector db for memory.","src/content/projects/shiro.md","a5202043d35fadba",{"html":274,"metadata":275},"\u003Cp>As someone constantly juggling new ideas, I suffer from “context overflow.” Just like an AI agent. I’m often managing multiple projects, scattered research, and half-finished thoughts—the constant context switching was killing my productivity.\u003C/p>\n\u003Cp>To solve this, I first built Mind Lake—a centralized knowledge system in Notion. It’s my single source of truth for every idea, project, and learning. It helped, but it wasn’t enough. I realized I didn’t just need a place to store info; I needed a system that understood my 2026 goals well enough to prioritize and unblock work for me.\u003C/p>\n\u003Cp>So, I spent the last 5 days building Shiro: my personal AI assistant powered by the Claude Agent SDK.\u003C/p>\n\u003Ch2 id=\"what-shiro-can-do\">What Shiro Can Do\u003C/h2>\n\u003Cul>\n\u003Cli>\u003Cstrong>Telegram Interface:\u003C/strong> I interact with Shiro via text, treating him like a high-level employee.\u003C/li>\n\u003Cli>\u003Cstrong>Notion Integration:\u003C/strong> He searches my Notion workspace to prioritize tasks based on my specific goals and deadlines.\u003C/li>\n\u003Cli>\u003Cstrong>Content Creation:\u003C/strong> Draft content for me based on my latest learning in my project.\u003C/li>\n\u003Cli>\u003Cstrong>Active Unblocking:\u003C/strong> Shiro asks why tasks are stalling and takes initiative—doing the research or suggesting ways to unblock it.\u003C/li>\n\u003Cli>\u003Cstrong>Daily Accountability:\u003C/strong> He sends a priority reminder every morning and a “check-in” every night to keep me on track.\u003C/li>\n\u003Cli>\u003Cstrong>Self-Evolving Memory:\u003C/strong> He learns from my patterns and develops new Claude Skills (modular prompts) to grow his own capabilities.\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Tech Stack:\u003C/strong> Python, Claude Agent SDK, Model Context Protocol (MCP), Docker, Fly.io\u003C/p>\n\u003Ch2 id=\"why-build-this\">Why Build This?\u003C/h2>\n\u003Cp>You would say why build an AI agent when some of the above can be achieved by Claude chat and Notion MCP? I have learnt so much in the past 5 days building this AI agent and it amazed me.\u003C/p>\n\u003Ch2 id=\"what-i-learned-shipping-it\">What I Learned Shipping It\u003C/h2>\n\u003Cp>\u003Cstrong>Agentic Minimalism:\u003C/strong> Don’t give your AI agents all the tools and let them pick from it. Define the tools well and when to use them. For example, when it comes to getting data from Notion, MCP is not the best way to get all my active tasks, it was way slower than direct Notion API, in the end I used a hybrid approach.\u003C/p>\n\u003Cp>\u003Cstrong>The Permission Guardrail:\u003C/strong> Early on, I gave Shiro full file write permissions. I was baffled to find new Python files appearing in my local project—turns out Shiro was building his own toolkit to do a better job! I had to implement strict guards. Now, he can only edit his memory and skills, but he cannot touch his core functions (Python files).\u003C/p>\n\u003Cp>\u003Cstrong>Dynamic nature of AI Agents:\u003C/strong> AI agent develops and grows, it would update its learnings and skills on the VM- syncing the ai agent would be key.\u003C/p>\n\u003Chr>\n\u003Cp>Building Shiro has completely evolved my understanding of AI development.\u003C/p>\n\u003Cp>I had so much fun building this, can’t wait to share more! Next would be to use a vector db for memory.\u003C/p>",{"headings":276,"localImagePaths":286,"remoteImagePaths":287,"frontmatter":288,"imagePaths":293},[277,280,283],{"depth":28,"slug":278,"text":279},"what-shiro-can-do","What Shiro Can Do",{"depth":28,"slug":281,"text":282},"why-build-this","Why Build This?",{"depth":28,"slug":284,"text":285},"what-i-learned-shipping-it","What I Learned Shipping It",[],[],{"title":252,"slug":249,"date":253,"date_pretty":254,"description":255,"importance":170,"type":29,"hero":289,"project":290,"seo":292},{"image":257,"alt":258},{"tags":291},[101,268,269],{"keywords":260,"og_image":257},[],"shiro.md","lumina-tarot",{"id":295,"data":297,"filePath":315,"digest":316,"rendered":317,"legacyId":328},{"title":298,"date":299,"date_pretty":300,"description":301,"external_link":302,"hero":303,"seo":306,"importance":65,"type":29,"project":312},"Lumina Tarot","2025-10-21","Oct 21, 2025","An AI-powered tarot reading web app built for the Cursor Hackathon,  using generative AI for visuals and LLMs for accurate, personalized readings.","https://www.lumina-tarot.com",{"image":304,"alt":305},"assets/lumina_tarot_project.png","A sleek tarot reading app that uses AI to generate personalized spreads and interpretations.",{"keywords":307,"og_image":304},[308,298,309,310,311],"AI Tarot","Tarot Readings","Cursor Hackathon","Generative AI",{"tags":313},[32,101,314,139],"elevenlabs","src/content/projects/lumina-tarot.md","ceffd86fd4d0d595",{"html":38,"metadata":318},{"headings":319,"localImagePaths":320,"remoteImagePaths":321,"frontmatter":322,"imagePaths":327},[],[],[],{"title":298,"slug":295,"date":299,"date_pretty":300,"description":301,"importance":65,"type":29,"external_link":302,"hero":323,"project":324,"seo":326},{"image":304,"alt":305},{"tags":325},[32,101,314,139],{"keywords":307,"og_image":304},[],"lumina-tarot.md","redflag",{"id":329,"data":331,"body":353,"filePath":354,"digest":355,"rendered":356,"legacyId":383},{"title":332,"date":333,"date_pretty":334,"description":335,"hero":336,"seo":341,"importance":170,"type":29,"project":349},"RedFlag","2026-02-01","Feb 01, 2026","An AI-powered scam detection tool that puts threat intelligence in the hands of everyday consumers.",{"image":337,"alt":338,"link":339,"link_text":340},"assets/redflag.png","RedFlag - An AI-powered scam detection tool with screenshot analysis, QR code scanning, and link verification.","https://redflag-bay.vercel.app","Try RedFlag",{"keywords":342,"og_image":337},[332,343,344,345,346,347,348],"Scam Detection","Fraud Detection","AI Agent","Gemini API","Phishing Detection","Consumer Security",{"tags":350},[32,101,351,352],"gemini api","fraud detection","Fraud is rampant. The US loses approximately US$34 million daily to scams; in Taiwan, the figure is US$8–9 million. Scam tactics are everywhere — and AI is helping bad actors become more sophisticated, more convincing, and harder to detect.\n\nIf AI is making offense better, we need to make defense better too. That's why I created RedFlag — a threat detection and risk assessment tool that puts the power of AI-driven scam analysis directly into the hands of everyday consumers.\n\n## What It Does\n\nRedFlag is a universal fraud detector. Screenshot a suspicious message or URL, or scan a QR code — an agentic Gemini investigation runs real security tools behind the scenes (WHOIS, DNS/GeoIP, Google Safe Browsing), then cross-references the technical evidence against the content's claims to surface red flags.\n\nRedFlag explains fraud through a 3-step narrative: the **hook** (what lured you), the **MO** (how the scam operates), and the **risk signals** (the technical evidence that proves it). Every fact shown in the UI — domain age, registrar, server location, registrant — comes from real API data, not model generation. The app works in 8 languages and auto-detects the user's locale.\n\nDrawing from my experience as a fraud analyst — building risk frameworks, fraud rules, and data infrastructure for enterprises — I mapped the consumer scam landscape into three core threat types:\n\n- **Phishing Links** — Fraudulent URLs designed to steal credentials or personal data by impersonating trusted websites, from crude fakes to near-perfect replicas of banking portals and government services.\n- **QR Code Scams** — A growing attack vector where malicious links hide behind QR codes. The consumer sees a seemingly legitimate code on a poster, in a message, or at a payment terminal, but scanning it redirects them to a phishing site.\n- **Social Engineering Scams** — Scams delivered through conversation: chat messages, SMS, emails, paper mail, or in-app messages. These rely on psychological manipulation — urgency, authority, fear, or trust — rather than technical exploits, making them the hardest to detect and the most damaging.\n\n## How I Built It\n\n- **Frontend:** React 19 + TypeScript SPA with Vite, Tailwind CSS, and Framer Motion\n- **Backend:** Vercel serverless functions with a single `/api/analyze` endpoint\n- **AI:** Gemini Interactions API (agentic multi-turn loop) — Gemini autonomously decides which security tools to call, executes them in parallel, then reasons across all results to produce a bilingual fraud analysis\n- **Intelligence Tools:** 4 backend tools (DNS/GeoIP, RDAP with registrar referral chain, Google Safe Browsing, homograph detection) that Gemini calls as needed\n- **Trust Layer:** Server-side `buildVerifiedFromToolResults()` constructs a verified data object from raw tool output, completely independent of the model's JSON response\n- **Logging:** Supabase for fire-and-forget analysis logging and user feedback tracking\n- **i18n:** Custom React Context provider with 8 locale files and browser language auto-detection\n\n## Challenges I Ran Into\n\n**Reliable phishing detection.** I discovered that WHOIS data and other publicly available domain intelligence can be used reliably for detection — domain age, registrar history, and hosting location tell a story before you ever load the page.\n\n**Building a unified analysis pipeline.** I initially built three separate API calls for each feature. Then I realised that these three checks are inherently similar — a URL is a URL whether it was typed, scanned from a QR code, or extracted from a screenshot. Switching to the Gemini Interactions API's agentic capabilities let the model decide which tools to call, eliminating redundant code and producing smarter, more context-aware analysis.\n\n**Designing for global users.** A user's language and location are independent from the scam's language and origin. A Singaporean travelling in Taiwan might encounter a Chinese-language fraud but still want to read the analysis in English — or in Chinese. The solution was dual-language output: analyse in the scam's native language for accuracy, then present in the user's preferred language for clarity.\n\n## What I'm Proud Of\n\n**From manual rules to agentic orchestration.** Traditional fraud detection requires understanding each category of fraud, learning its patterns, then manually creating data features or ML models to detect them. With RedFlag, the paradigm shifts — orchestrating an AI agent with the right tools means the system can reason across fraud categories rather than being hard-coded for each one.\n\n**The 3-step fraud narrative.** Hook, MO, and risk signals make fraud understandable to non-technical users. It's not a risk score — it's a story that teaches people how scams actually work, with actionable next steps they can take immediately.\n\n**Geo-mismatch detection.** Cross-referencing server hosting country against registrant country against the brand being impersonated catches sophisticated phishing that no single check would flag.\n\n**The verified data layer.** Gemini reasons about fraud, but the Digital Fingerprint grid shows only real data from actual API responses. This separation means users never see hallucinated facts — a \"registered 3 days ago\" claim is provably true.\n\n**Screenshot-first input.** Asking someone to paste a suspicious link — and risk accidentally clicking it — defeats the purpose. This was a design decision rooted in user safety.\n\n**Dual-mode fallback.** The Interactions API is in beta and can fail. I built a complete legacy path using `generateContent` that shares the same system prompt, response schema, and verified data pipeline — so if the agentic path errors, users still get a full analysis without knowing anything went wrong.\n\n## What I Learned\n\n- **Agentic AI is a paradigm shift.** Letting the model drive tool selection produces smarter, more adaptive analysis than pre-calling everything or routing through separate APIs.\n- **Open infrastructure is underrated.** Free tools like IANA RDAP, DNS-over-HTTPS, and GeoIP databases can replace expensive commercial threat intel APIs for most fraud detection use cases.\n- **Security hygiene matters in consumer apps.** Moving API keys from client-side to server-side, implementing rate limiting, and supporting multi-language output were all lessons learned through building rather than theory.\n\n---\n\n- [Try RedFlag](https://redflag-bay.vercel.app)\n- [Architecture](https://redflag-bay.vercel.app/#/architecture)","src/content/projects/redflag.md","278019c07115b45d",{"html":357,"metadata":358},"\u003Cp>Fraud is rampant. The US loses approximately US$34 million daily to scams; in Taiwan, the figure is US$8–9 million. Scam tactics are everywhere — and AI is helping bad actors become more sophisticated, more convincing, and harder to detect.\u003C/p>\n\u003Cp>If AI is making offense better, we need to make defense better too. That’s why I created RedFlag — a threat detection and risk assessment tool that puts the power of AI-driven scam analysis directly into the hands of everyday consumers.\u003C/p>\n\u003Ch2 id=\"what-it-does\">What It Does\u003C/h2>\n\u003Cp>RedFlag is a universal fraud detector. Screenshot a suspicious message or URL, or scan a QR code — an agentic Gemini investigation runs real security tools behind the scenes (WHOIS, DNS/GeoIP, Google Safe Browsing), then cross-references the technical evidence against the content’s claims to surface red flags.\u003C/p>\n\u003Cp>RedFlag explains fraud through a 3-step narrative: the \u003Cstrong>hook\u003C/strong> (what lured you), the \u003Cstrong>MO\u003C/strong> (how the scam operates), and the \u003Cstrong>risk signals\u003C/strong> (the technical evidence that proves it). Every fact shown in the UI — domain age, registrar, server location, registrant — comes from real API data, not model generation. The app works in 8 languages and auto-detects the user’s locale.\u003C/p>\n\u003Cp>Drawing from my experience as a fraud analyst — building risk frameworks, fraud rules, and data infrastructure for enterprises — I mapped the consumer scam landscape into three core threat types:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Phishing Links\u003C/strong> — Fraudulent URLs designed to steal credentials or personal data by impersonating trusted websites, from crude fakes to near-perfect replicas of banking portals and government services.\u003C/li>\n\u003Cli>\u003Cstrong>QR Code Scams\u003C/strong> — A growing attack vector where malicious links hide behind QR codes. The consumer sees a seemingly legitimate code on a poster, in a message, or at a payment terminal, but scanning it redirects them to a phishing site.\u003C/li>\n\u003Cli>\u003Cstrong>Social Engineering Scams\u003C/strong> — Scams delivered through conversation: chat messages, SMS, emails, paper mail, or in-app messages. These rely on psychological manipulation — urgency, authority, fear, or trust — rather than technical exploits, making them the hardest to detect and the most damaging.\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"how-i-built-it\">How I Built It\u003C/h2>\n\u003Cul>\n\u003Cli>\u003Cstrong>Frontend:\u003C/strong> React 19 + TypeScript SPA with Vite, Tailwind CSS, and Framer Motion\u003C/li>\n\u003Cli>\u003Cstrong>Backend:\u003C/strong> Vercel serverless functions with a single \u003Ccode>/api/analyze\u003C/code> endpoint\u003C/li>\n\u003Cli>\u003Cstrong>AI:\u003C/strong> Gemini Interactions API (agentic multi-turn loop) — Gemini autonomously decides which security tools to call, executes them in parallel, then reasons across all results to produce a bilingual fraud analysis\u003C/li>\n\u003Cli>\u003Cstrong>Intelligence Tools:\u003C/strong> 4 backend tools (DNS/GeoIP, RDAP with registrar referral chain, Google Safe Browsing, homograph detection) that Gemini calls as needed\u003C/li>\n\u003Cli>\u003Cstrong>Trust Layer:\u003C/strong> Server-side \u003Ccode>buildVerifiedFromToolResults()\u003C/code> constructs a verified data object from raw tool output, completely independent of the model’s JSON response\u003C/li>\n\u003Cli>\u003Cstrong>Logging:\u003C/strong> Supabase for fire-and-forget analysis logging and user feedback tracking\u003C/li>\n\u003Cli>\u003Cstrong>i18n:\u003C/strong> Custom React Context provider with 8 locale files and browser language auto-detection\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"challenges-i-ran-into\">Challenges I Ran Into\u003C/h2>\n\u003Cp>\u003Cstrong>Reliable phishing detection.\u003C/strong> I discovered that WHOIS data and other publicly available domain intelligence can be used reliably for detection — domain age, registrar history, and hosting location tell a story before you ever load the page.\u003C/p>\n\u003Cp>\u003Cstrong>Building a unified analysis pipeline.\u003C/strong> I initially built three separate API calls for each feature. Then I realised that these three checks are inherently similar — a URL is a URL whether it was typed, scanned from a QR code, or extracted from a screenshot. Switching to the Gemini Interactions API’s agentic capabilities let the model decide which tools to call, eliminating redundant code and producing smarter, more context-aware analysis.\u003C/p>\n\u003Cp>\u003Cstrong>Designing for global users.\u003C/strong> A user’s language and location are independent from the scam’s language and origin. A Singaporean travelling in Taiwan might encounter a Chinese-language fraud but still want to read the analysis in English — or in Chinese. The solution was dual-language output: analyse in the scam’s native language for accuracy, then present in the user’s preferred language for clarity.\u003C/p>\n\u003Ch2 id=\"what-im-proud-of\">What I’m Proud Of\u003C/h2>\n\u003Cp>\u003Cstrong>From manual rules to agentic orchestration.\u003C/strong> Traditional fraud detection requires understanding each category of fraud, learning its patterns, then manually creating data features or ML models to detect them. With RedFlag, the paradigm shifts — orchestrating an AI agent with the right tools means the system can reason across fraud categories rather than being hard-coded for each one.\u003C/p>\n\u003Cp>\u003Cstrong>The 3-step fraud narrative.\u003C/strong> Hook, MO, and risk signals make fraud understandable to non-technical users. It’s not a risk score — it’s a story that teaches people how scams actually work, with actionable next steps they can take immediately.\u003C/p>\n\u003Cp>\u003Cstrong>Geo-mismatch detection.\u003C/strong> Cross-referencing server hosting country against registrant country against the brand being impersonated catches sophisticated phishing that no single check would flag.\u003C/p>\n\u003Cp>\u003Cstrong>The verified data layer.\u003C/strong> Gemini reasons about fraud, but the Digital Fingerprint grid shows only real data from actual API responses. This separation means users never see hallucinated facts — a “registered 3 days ago” claim is provably true.\u003C/p>\n\u003Cp>\u003Cstrong>Screenshot-first input.\u003C/strong> Asking someone to paste a suspicious link — and risk accidentally clicking it — defeats the purpose. This was a design decision rooted in user safety.\u003C/p>\n\u003Cp>\u003Cstrong>Dual-mode fallback.\u003C/strong> The Interactions API is in beta and can fail. I built a complete legacy path using \u003Ccode>generateContent\u003C/code> that shares the same system prompt, response schema, and verified data pipeline — so if the agentic path errors, users still get a full analysis without knowing anything went wrong.\u003C/p>\n\u003Ch2 id=\"what-i-learned\">What I Learned\u003C/h2>\n\u003Cul>\n\u003Cli>\u003Cstrong>Agentic AI is a paradigm shift.\u003C/strong> Letting the model drive tool selection produces smarter, more adaptive analysis than pre-calling everything or routing through separate APIs.\u003C/li>\n\u003Cli>\u003Cstrong>Open infrastructure is underrated.\u003C/strong> Free tools like IANA RDAP, DNS-over-HTTPS, and GeoIP databases can replace expensive commercial threat intel APIs for most fraud detection use cases.\u003C/li>\n\u003Cli>\u003Cstrong>Security hygiene matters in consumer apps.\u003C/strong> Moving API keys from client-side to server-side, implementing rate limiting, and supporting multi-language output were all lessons learned through building rather than theory.\u003C/li>\n\u003C/ul>\n\u003Chr>\n\u003Cul>\n\u003Cli>\u003Ca href=\"https://redflag-bay.vercel.app\">Try RedFlag\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"https://redflag-bay.vercel.app/#/architecture\">Architecture\u003C/a>\u003C/li>\n\u003C/ul>",{"headings":359,"localImagePaths":375,"remoteImagePaths":376,"frontmatter":377,"imagePaths":382},[360,363,366,369,372],{"depth":28,"slug":361,"text":362},"what-it-does","What It Does",{"depth":28,"slug":364,"text":365},"how-i-built-it","How I Built It",{"depth":28,"slug":367,"text":368},"challenges-i-ran-into","Challenges I Ran Into",{"depth":28,"slug":370,"text":371},"what-im-proud-of","What I’m Proud Of",{"depth":28,"slug":373,"text":374},"what-i-learned","What I Learned",[],[],{"title":332,"slug":329,"date":333,"date_pretty":334,"description":335,"importance":170,"type":29,"hero":378,"project":379,"seo":381},{"image":337,"alt":338,"link":339,"link_text":340},{"tags":380},[32,101,351,352],{"keywords":342,"og_image":337},[],"redflag.md","tarot-meow",{"id":384,"data":386,"body":403,"filePath":404,"digest":405,"rendered":406,"legacyId":421},{"title":387,"date":333,"date_pretty":388,"description":389,"external_link":390,"hero":391,"seo":394,"importance":170,"type":29,"project":400},"TarotMeow","Feb 1, 2026","A 3D tarot reading experience that won 2nd Place at the APAC Art x Tech Hackathon — featuring an infinite spiral scroll through 78 cards with AI-powered personalized readings.","https://www.tarotmeow.com",{"image":392,"alt":393},"assets/tarotmeow.png","TarotMeow — a 3D tarot reading experience with cat-themed cards arranged in an infinite spiral tunnel.",{"keywords":395,"og_image":392},[387,396,397,398,399,311],"3D Tarot","AI Tarot Reading","React Three Fiber","APAC Art x Tech Hackathon",{"tags":401},[32,101,225,402],"react three fiber","Won 2nd Place at the APAC Art x Tech Hackathon.\n\n**The challenge:** Display 78 tarot cards on a mobile screen without losing the immersive, personal feeling of a real reading.\n\n**My solution:** An infinite depth scroll that arranges the entire deck into a spiral tunnel. As you scroll, you travel through the cards. An AI voice guide walks you through the draw, then delivers a personalized reading based on your question and chosen cards.\n\n## Tech Stack\n\n- **React Three Fiber** — 3D spatial architecture\n- **OpenAI + n8n** — cat-themed tarot card generation\n- **Google Gemini 2.5 Flash** — contextual readings\n- **ElevenLabs** — immersive voice narration\n\nThis project sits at the intersection of what I love: solving creative UI constraints and adopting AI tools to create experiences that feel magical.\n\n---\n\n- [Live Demo](https://www.tarotmeow.com)","src/content/projects/tarot-meow.md","bb351fdc96929bf1",{"html":407,"metadata":408},"\u003Cp>Won 2nd Place at the APAC Art x Tech Hackathon.\u003C/p>\n\u003Cp>\u003Cstrong>The challenge:\u003C/strong> Display 78 tarot cards on a mobile screen without losing the immersive, personal feeling of a real reading.\u003C/p>\n\u003Cp>\u003Cstrong>My solution:\u003C/strong> An infinite depth scroll that arranges the entire deck into a spiral tunnel. As you scroll, you travel through the cards. An AI voice guide walks you through the draw, then delivers a personalized reading based on your question and chosen cards.\u003C/p>\n\u003Ch2 id=\"tech-stack\">Tech Stack\u003C/h2>\n\u003Cul>\n\u003Cli>\u003Cstrong>React Three Fiber\u003C/strong> — 3D spatial architecture\u003C/li>\n\u003Cli>\u003Cstrong>OpenAI + n8n\u003C/strong> — cat-themed tarot card generation\u003C/li>\n\u003Cli>\u003Cstrong>Google Gemini 2.5 Flash\u003C/strong> — contextual readings\u003C/li>\n\u003Cli>\u003Cstrong>ElevenLabs\u003C/strong> — immersive voice narration\u003C/li>\n\u003C/ul>\n\u003Cp>This project sits at the intersection of what I love: solving creative UI constraints and adopting AI tools to create experiences that feel magical.\u003C/p>\n\u003Chr>\n\u003Cul>\n\u003Cli>\u003Ca href=\"https://www.tarotmeow.com\">Live Demo\u003C/a>\u003C/li>\n\u003C/ul>",{"headings":409,"localImagePaths":413,"remoteImagePaths":414,"frontmatter":415,"imagePaths":420},[410],{"depth":28,"slug":411,"text":412},"tech-stack","Tech Stack",[],[],{"title":387,"slug":384,"date":333,"date_pretty":388,"description":389,"importance":170,"type":29,"external_link":390,"hero":416,"project":417,"seo":419},{"image":392,"alt":393},{"tags":418},[32,101,225,402],{"keywords":395,"og_image":392},[],"tarot-meow.md","visualise-spending",{"id":422,"data":424,"body":70,"filePath":476,"digest":477,"rendered":478,"legacyId":499},{"title":425,"date":426,"date_pretty":427,"description":428,"external_link":429,"hero":430,"gallery":435,"content_blocks":458,"seo":467,"importance":28,"type":29,"project":472},"Visualizing Singapore Government Spending","2019-01-01","Jan 1, 2019","Insights into how ministries and agencies spend, with visual analytics","https://wiki.smu.edu.sg/18191is428g1/GeViz",{"image":431,"alt":432,"link":433,"link_text":434},"assets/Geviz_project_cover.png","Singapore government spending dashboard showing budget allocation across ministries with interactive charts","https://is428-ay1819-geviz.shinyapps.io/Group7_GeViz/","View Live Project",{"layout":436,"columns":28,"items":437},"masonry",[438,443,448,453],{"src":439,"title":440,"alt":441,"caption":442},"assets/geviz/treemap.png","An Overview of Agency Spending within Each Ministry","Overview","Treemap chart is used here to provide a birds-eye view of each each ministry's spending breakdown by agency and category. The size of the box represents number of procurement contracts of each procurement category while the colour intensity represents the total amount of good and services procured.",{"src":444,"title":445,"alt":446,"caption":447},"assets/geviz/network.jpeg","Relationships Between Agencies and Suppliers","Breakdown","To best represent the interlinked relationship beteewen suppliers and agencies under a selected ministry, network diagram was used to shows the common suppliers between agencies. The triangle icon represents agencies while the circle icon represents suppliers.",{"src":449,"title":450,"alt":451,"caption":452},"assets/geviz/sangkey.jpeg","Main Suppliers of an Agency by Spending Category","Sankey","This sankey diagram was created with R's NetworkD3 library, the chart shows the cash flow between a selected agency and its suppliers for a selected procurement category. The thickness of the path represents the total dollar amount of goods and services procured from a particular supplier.",{"src":454,"title":455,"alt":456,"caption":457},"assets/geviz/wordcloud.jpeg","A Glimpse into Goods and Services Procured","Word cloud","This word cloud was created with R's Wordcloud2 library, it shows the top goods and services procured by a selected agency and a selected category. The size of the word within the word cloud corresponds to the frequency of the word in the procurement descriptions.",[459,462,465],{"type":460,"level":65,"text":461},"heading","Project Overview",{"type":463,"text":464},"paragraph","How do you make sense of billions in government spending? Singapore's government budget data is publicly available, but buried in dense spreadsheets. We built an interactive dashboard using R Shiny that transforms Singapore's complex budget data into clear, explorable visualizations.",{"type":463,"text":466},"Read the complete project [here](https://wiki.smu.edu.sg/18191is428g1/GeViz)",{"keywords":468,"og_image":431},[469,470,471],"Dashboard","R Shiny","Working in progress",{"tags":473},[68,474,475],"r shiny","dashboard","src/content/projects/visualise-spending.md","90e21b1ab776ec97",{"html":70,"metadata":479},{"headings":480,"localImagePaths":481,"remoteImagePaths":482,"frontmatter":483,"imagePaths":498},[],[],[],{"title":425,"slug":422,"date":426,"date_pretty":427,"description":428,"importance":28,"type":29,"external_link":429,"hero":484,"project":485,"content_blocks":487,"gallery":491,"seo":497},{"image":431,"alt":432,"link":433,"link_text":434},{"tags":486},[68,474,475],[488,489,490],{"type":460,"level":65,"text":461},{"type":463,"text":464},{"type":463,"text":466},{"layout":436,"columns":28,"items":492},[493,494,495,496],{"src":439,"title":440,"alt":441,"caption":442},{"src":444,"title":445,"alt":446,"caption":447},{"src":449,"title":450,"alt":451,"caption":452},{"src":454,"title":455,"alt":456,"caption":457},{"keywords":468,"og_image":431},[],"visualise-spending.md","posts",["Map",502,503,527,528],"prompt-engineering",{"id":502,"data":504,"body":70,"filePath":515,"digest":516,"rendered":517,"legacyId":526},{"title":505,"date":506,"date_pretty":507,"description":508,"seo":509,"type":512,"tags":513},"Notes on prompt engineering","2025-09-08","Sep 8, 2025"," My cheatsheet on prompt engineering from Google's whitepaper",{"keywords":510},[511],"Coming soon","post",[511,514],"Draft","src/content/posts/prompt-engineering.md","a5502abac0ece68a",{"html":70,"metadata":518},{"headings":519,"localImagePaths":520,"remoteImagePaths":521,"frontmatter":522,"imagePaths":525},[],[],[],{"title":505,"slug":502,"date":506,"date_pretty":507,"description":508,"type":512,"tags":523,"seo":524},[511,514],{"keywords":510},[],"prompt-engineering.md","vibe-coding-portfolio",{"id":527,"data":529,"body":544,"filePath":545,"digest":546,"rendered":547,"legacyId":594},{"title":530,"date":531,"date_pretty":532,"description":533,"seo":534,"type":512,"tags":540},"What I Learned Vibe Coding My Portfolio in 4 Days","2025-09-20","Sep 20, 2025","Lessons on taste, prompting, frameworks, and building a portfolio website with Codex",{"keywords":535},[536,537,538,539],"AI portfolio building","prompt engineering","vibe coding","Astro framework",[541,542,543],"Vibe Coding","Prompting","Learning","## The Discovery Process: Learning What to Ask\n\nI started building this portfolio website with a Wix resume template as inspiration, asking LLM questions as I went. While this iterative approach worked, I only realized what I truly wanted to build after several rounds of implementation.\n\nThe process taught me something valuable: I should have first considered which framework, design approach and content management strategy to adopt.\n\nWhen I realized that I needed markdown support for blog posts, I had to migrate to a new framework—not because I didn't plan, but because I didn't know the right questions to ask initially.\n\n## AI Can't Give You Taste\n\nAI can only build what you ask for. Since I based my design on a resume-like template, my software engineer friends told me: \"This looks like a resume. You might as well not build one.\"\n\nThey gave me a few portfolio references that worked—minimalistic, compact, and functional designs that matched my goals. After studying these examples, I spent another day rebuilding the entire homepage based on the new reference.\n\nThat's when I realized I needed to define my taste, styling, and purpose clearly before starting—because the effort to rebuild is high. (The specific questions I should have asked are covered in my framework below.)\n\n## Trial and Error: What Works for AI-Assisted Coding\n\nI started with Claude, hit rate limits, then switched to Codex (ChatGPT Plus). But real progress came when I switched from terminal-based prompting to the Codex plugin in VS Code.\n\nThe VS Code plugin was easy to use—it allowed me to upload reference images easily, made reviewing conversation history seamless, and made iterating on code efficient.\n\nI discovered that:\n\n- **Screenshot-to-code translation**: Codex could convert UI screenshots into functional code with ~80% accuracy. You can also paste website URLs into your prompt as reference.\n- **Debugging specificity**: Basic HTML/CSS knowledge helped me give precise feedback. Codex understands better when you say 'Move the experience-description into the first column of the grid' than 'Move the experience-description to the left side of the box.'\n- **Planning vs. agent mode**: Define requirements in planning mode before implementing in agent mode to prevent unnecessary rework.\n\n## Building Production-Quality Code with AI\n\nWhile building this project, I faced another challenge: getting AI to write quality code. LLMs build like enthusiastic juniors—functional but lacking production standards. They won't automatically include:\n\n- CSS variables for consistent styling\n- Mobile responsiveness\n- Automated code cleaning whenever you rebuild or migrate frameworks\n- Comprehensive README\n- Logical file organization based on your web framework\n- Creating reusable page templates and components to keep your styling consistent\n\nYou have to ask for all of the above explicitly.\n\n## Your Website's Purpose Determines Your Tech Stack\n\nJust when I thought I was done building, I hit a fundamental problem: I had chosen the wrong tech stack. Adding new content meant updating JSON files, which quickly became cumbersome to maintain.\n\nMy friend suggested using GitHub markdown as an easier solution, but my vanilla HTML/CSS setup couldn't handle markdown files gracefully. Every new post triggered layout bugs.\n\nThat's when I learned that your website's purpose should drive your tech stack choice—this should be the first question you ask. I needed a framework built for markdown content, which led me to Astro with its native markdown support, file-based routing, and static generation.\n\n### Additional Learnings\n\nBeyond the core lessons, this project taught me about other development skills.\n\n- **Version control fluency**: Writing meaningful commit messages and revisiting Git workflows\n- **Deployment processes**: Learning Astro deployment and hosting options\n- **CMS ecosystem knowledge**: Understanding different types of CMS systems from file-based to headless CMS solutions\n\n## &nbsp;\n\n---\n\n## The Questions I Wish I'd Asked First\n\nAsk these questions before building anything:\n\n#### Design & Vision\n\n- What websites do I want mine to look and feel like? Pick 1 or 2 websites\n- What specific elements do I want to steal? (Screenshot specific elements: nav style, button design, color palette, typography)\n- What’s the main thing I want visitors to do? (Contact me, view my work, read my writing)\n- What's my content hierarchy? (What should visitors see first, second, third?)\n\n#### Tech Stack & Tools\n\n- Do I want a simple blog, a portfolio showcase, or something more complex?\n- Where will I host this? (GitHub, Vercel, etc.)\n- How will I handle version control? (GitHub Desktop, Git basics)\n\n#### Content Strategy\n\n- How often I update affects framework choice:\n  - Daily/weekly → fast and simple (Astro with markdown)\n  - Monthly → static generation is fine\n- How I update determines tech stack:\n  - Markdown → Astro, Next.js\n  - JSON → Static generators\n  - CMS → Headless CMS + framework\n- Visitor interaction needs affect hosting decisions:\n  - None → Static hosting (GitHub Pages, Netlify)\n  - Comments/forms → Backend services or integrations\n  - Accounts → Database + auth system\n\n#### Quality Code\n\n- What are the key steps to ensure my code is good? (Fast loading, responsive, clean code)\n\n## Reflection\n\nWorking on this vibe coding project was incredibly fun. While some rework was inevitable, the learning made it worthwhile. I hope this framework helps you build faster and more intentionally on your next project.\n\nHappy building!","src/content/posts/vibe-coding.md","72d0cefc7d4e0cfc",{"html":548,"metadata":549},"\u003Ch2 id=\"the-discovery-process-learning-what-to-ask\">The Discovery Process: Learning What to Ask\u003C/h2>\n\u003Cp>I started building this portfolio website with a Wix resume template as inspiration, asking LLM questions as I went. While this iterative approach worked, I only realized what I truly wanted to build after several rounds of implementation.\u003C/p>\n\u003Cp>The process taught me something valuable: I should have first considered which framework, design approach and content management strategy to adopt.\u003C/p>\n\u003Cp>When I realized that I needed markdown support for blog posts, I had to migrate to a new framework—not because I didn’t plan, but because I didn’t know the right questions to ask initially.\u003C/p>\n\u003Ch2 id=\"ai-cant-give-you-taste\">AI Can’t Give You Taste\u003C/h2>\n\u003Cp>AI can only build what you ask for. Since I based my design on a resume-like template, my software engineer friends told me: “This looks like a resume. You might as well not build one.”\u003C/p>\n\u003Cp>They gave me a few portfolio references that worked—minimalistic, compact, and functional designs that matched my goals. After studying these examples, I spent another day rebuilding the entire homepage based on the new reference.\u003C/p>\n\u003Cp>That’s when I realized I needed to define my taste, styling, and purpose clearly before starting—because the effort to rebuild is high. (The specific questions I should have asked are covered in my framework below.)\u003C/p>\n\u003Ch2 id=\"trial-and-error-what-works-for-ai-assisted-coding\">Trial and Error: What Works for AI-Assisted Coding\u003C/h2>\n\u003Cp>I started with Claude, hit rate limits, then switched to Codex (ChatGPT Plus). But real progress came when I switched from terminal-based prompting to the Codex plugin in VS Code.\u003C/p>\n\u003Cp>The VS Code plugin was easy to use—it allowed me to upload reference images easily, made reviewing conversation history seamless, and made iterating on code efficient.\u003C/p>\n\u003Cp>I discovered that:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Screenshot-to-code translation\u003C/strong>: Codex could convert UI screenshots into functional code with ~80% accuracy. You can also paste website URLs into your prompt as reference.\u003C/li>\n\u003Cli>\u003Cstrong>Debugging specificity\u003C/strong>: Basic HTML/CSS knowledge helped me give precise feedback. Codex understands better when you say ‘Move the experience-description into the first column of the grid’ than ‘Move the experience-description to the left side of the box.’\u003C/li>\n\u003Cli>\u003Cstrong>Planning vs. agent mode\u003C/strong>: Define requirements in planning mode before implementing in agent mode to prevent unnecessary rework.\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"building-production-quality-code-with-ai\">Building Production-Quality Code with AI\u003C/h2>\n\u003Cp>While building this project, I faced another challenge: getting AI to write quality code. LLMs build like enthusiastic juniors—functional but lacking production standards. They won’t automatically include:\u003C/p>\n\u003Cul>\n\u003Cli>CSS variables for consistent styling\u003C/li>\n\u003Cli>Mobile responsiveness\u003C/li>\n\u003Cli>Automated code cleaning whenever you rebuild or migrate frameworks\u003C/li>\n\u003Cli>Comprehensive README\u003C/li>\n\u003Cli>Logical file organization based on your web framework\u003C/li>\n\u003Cli>Creating reusable page templates and components to keep your styling consistent\u003C/li>\n\u003C/ul>\n\u003Cp>You have to ask for all of the above explicitly.\u003C/p>\n\u003Ch2 id=\"your-websites-purpose-determines-your-tech-stack\">Your Website’s Purpose Determines Your Tech Stack\u003C/h2>\n\u003Cp>Just when I thought I was done building, I hit a fundamental problem: I had chosen the wrong tech stack. Adding new content meant updating JSON files, which quickly became cumbersome to maintain.\u003C/p>\n\u003Cp>My friend suggested using GitHub markdown as an easier solution, but my vanilla HTML/CSS setup couldn’t handle markdown files gracefully. Every new post triggered layout bugs.\u003C/p>\n\u003Cp>That’s when I learned that your website’s purpose should drive your tech stack choice—this should be the first question you ask. I needed a framework built for markdown content, which led me to Astro with its native markdown support, file-based routing, and static generation.\u003C/p>\n\u003Ch3 id=\"additional-learnings\">Additional Learnings\u003C/h3>\n\u003Cp>Beyond the core lessons, this project taught me about other development skills.\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Version control fluency\u003C/strong>: Writing meaningful commit messages and revisiting Git workflows\u003C/li>\n\u003Cli>\u003Cstrong>Deployment processes\u003C/strong>: Learning Astro deployment and hosting options\u003C/li>\n\u003Cli>\u003Cstrong>CMS ecosystem knowledge\u003C/strong>: Understanding different types of CMS systems from file-based to headless CMS solutions\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"\"> \u003C/h2>\n\u003Chr>\n\u003Ch2 id=\"the-questions-i-wish-id-asked-first\">The Questions I Wish I’d Asked First\u003C/h2>\n\u003Cp>Ask these questions before building anything:\u003C/p>\n\u003Ch4 id=\"design--vision\">Design &#x26; Vision\u003C/h4>\n\u003Cul>\n\u003Cli>What websites do I want mine to look and feel like? Pick 1 or 2 websites\u003C/li>\n\u003Cli>What specific elements do I want to steal? (Screenshot specific elements: nav style, button design, color palette, typography)\u003C/li>\n\u003Cli>What’s the main thing I want visitors to do? (Contact me, view my work, read my writing)\u003C/li>\n\u003Cli>What’s my content hierarchy? (What should visitors see first, second, third?)\u003C/li>\n\u003C/ul>\n\u003Ch4 id=\"tech-stack--tools\">Tech Stack &#x26; Tools\u003C/h4>\n\u003Cul>\n\u003Cli>Do I want a simple blog, a portfolio showcase, or something more complex?\u003C/li>\n\u003Cli>Where will I host this? (GitHub, Vercel, etc.)\u003C/li>\n\u003Cli>How will I handle version control? (GitHub Desktop, Git basics)\u003C/li>\n\u003C/ul>\n\u003Ch4 id=\"content-strategy\">Content Strategy\u003C/h4>\n\u003Cul>\n\u003Cli>How often I update affects framework choice:\n\u003Cul>\n\u003Cli>Daily/weekly → fast and simple (Astro with markdown)\u003C/li>\n\u003Cli>Monthly → static generation is fine\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>How I update determines tech stack:\n\u003Cul>\n\u003Cli>Markdown → Astro, Next.js\u003C/li>\n\u003Cli>JSON → Static generators\u003C/li>\n\u003Cli>CMS → Headless CMS + framework\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>Visitor interaction needs affect hosting decisions:\n\u003Cul>\n\u003Cli>None → Static hosting (GitHub Pages, Netlify)\u003C/li>\n\u003Cli>Comments/forms → Backend services or integrations\u003C/li>\n\u003Cli>Accounts → Database + auth system\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch4 id=\"quality-code\">Quality Code\u003C/h4>\n\u003Cul>\n\u003Cli>What are the key steps to ensure my code is good? (Fast loading, responsive, clean code)\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"reflection\">Reflection\u003C/h2>\n\u003Cp>Working on this vibe coding project was incredibly fun. While some rework was inevitable, the learning made it worthwhile. I hope this framework helps you build faster and more intentionally on your next project.\u003C/p>\n\u003Cp>Happy building!\u003C/p>",{"headings":550,"localImagePaths":588,"remoteImagePaths":589,"frontmatter":590,"imagePaths":593},[551,554,557,560,563,566,569,571,574,577,580,582,585],{"depth":28,"slug":552,"text":553},"the-discovery-process-learning-what-to-ask","The Discovery Process: Learning What to Ask",{"depth":28,"slug":555,"text":556},"ai-cant-give-you-taste","AI Can’t Give You Taste",{"depth":28,"slug":558,"text":559},"trial-and-error-what-works-for-ai-assisted-coding","Trial and Error: What Works for AI-Assisted Coding",{"depth":28,"slug":561,"text":562},"building-production-quality-code-with-ai","Building Production-Quality Code with AI",{"depth":28,"slug":564,"text":565},"your-websites-purpose-determines-your-tech-stack","Your Website’s Purpose Determines Your Tech Stack",{"depth":65,"slug":567,"text":568},"additional-learnings","Additional Learnings",{"depth":28,"slug":38,"text":570}," ",{"depth":28,"slug":572,"text":573},"the-questions-i-wish-id-asked-first","The Questions I Wish I’d Asked First",{"depth":135,"slug":575,"text":576},"design--vision","Design & Vision",{"depth":135,"slug":578,"text":579},"tech-stack--tools","Tech Stack & Tools",{"depth":135,"slug":581,"text":167},"content-strategy",{"depth":135,"slug":583,"text":584},"quality-code","Quality Code",{"depth":28,"slug":586,"text":587},"reflection","Reflection",[],[],{"title":530,"slug":527,"date":531,"date_pretty":532,"description":533,"type":512,"tags":591,"seo":592},[541,542,543],{"keywords":535},[],"vibe-coding.md"]